{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Exercise M1.02\n",
    "\n",
    "The goal of this exercise is to fit a similar model as in the previous\n",
    "notebook to get familiar with manipulating scikit-learn objects and in\n",
    "particular the `.fit/.predict/.score` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the adult census dataset with only numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"./adult-census-numeric.csv\")\n",
    "data = adult_census.drop(columns=\"class\")\n",
    "target = adult_census[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe470526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39073 entries, 0 to 39072\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             39073 non-null  int64 \n",
      " 1   capital-gain    39073 non-null  int64 \n",
      " 2   capital-loss    39073 non-null  int64 \n",
      " 3   hours-per-week  39073 non-null  int64 \n",
      " 4   class           39073 non-null  object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "adult_census.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook we used `model = KNeighborsClassifier()`. All\n",
    "scikit-learn models can be created without arguments. This is convenient\n",
    "because it means that you don't need to understand the full details of a model\n",
    "before starting to use it.\n",
    "\n",
    "One of the `KNeighborsClassifier` parameters is `n_neighbors`. It controls the\n",
    "number of neighbors we are going to use to make a prediction for a new data\n",
    "point.\n",
    "\n",
    "What is the default value of the `n_neighbors` parameter?\n",
    "\n",
    "**Hint**: Look at the documentation on the [scikit-learn\n",
    "website](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "or directly access the description inside your notebook by running the\n",
    "following cell. This opens a pager pointing to the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "KNeighborsClassifier(\n",
      "    n_neighbors=\u001b[32m5\u001b[39m,\n",
      "    *,\n",
      "    weights=\u001b[33m'uniform'\u001b[39m,\n",
      "    algorithm=\u001b[33m'auto'\u001b[39m,\n",
      "    leaf_size=\u001b[32m30\u001b[39m,\n",
      "    p=\u001b[32m2\u001b[39m,\n",
      "    metric=\u001b[33m'minkowski'\u001b[39m,\n",
      "    metric_params=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    n_jobs=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ")\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "Classifier implementing the k-nearest neighbors vote.\n",
      "\n",
      "Read more in the :ref:`User Guide <classification>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_neighbors : int, default=5\n",
      "    Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      "\n",
      "weights : {'uniform', 'distance'}, callable or None, default='uniform'\n",
      "    Weight function used in prediction.  Possible values:\n",
      "\n",
      "    - 'uniform' : uniform weights.  All points in each neighborhood\n",
      "      are weighted equally.\n",
      "    - 'distance' : weight points by the inverse of their distance.\n",
      "      in this case, closer neighbors of a query point will have a\n",
      "      greater influence than neighbors which are further away.\n",
      "    - [callable] : a user-defined function which accepts an\n",
      "      array of distances, and returns an array of the same shape\n",
      "      containing the weights.\n",
      "\n",
      "    Refer to the example entitled\n",
      "    :ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`\n",
      "    showing the impact of the `weights` parameter on the decision\n",
      "    boundary.\n",
      "\n",
      "algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      "    Algorithm used to compute the nearest neighbors:\n",
      "\n",
      "    - 'ball_tree' will use :class:`BallTree`\n",
      "    - 'kd_tree' will use :class:`KDTree`\n",
      "    - 'brute' will use a brute-force search.\n",
      "    - 'auto' will attempt to decide the most appropriate algorithm\n",
      "      based on the values passed to :meth:`fit` method.\n",
      "\n",
      "    Note: fitting on sparse input will override the setting of\n",
      "    this parameter, using brute force.\n",
      "\n",
      "leaf_size : int, default=30\n",
      "    Leaf size passed to BallTree or KDTree.  This can affect the\n",
      "    speed of the construction and query, as well as the memory\n",
      "    required to store the tree.  The optimal value depends on the\n",
      "    nature of the problem.\n",
      "\n",
      "p : float, default=2\n",
      "    Power parameter for the Minkowski metric. When p = 1, this is equivalent\n",
      "    to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.\n",
      "    For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected\n",
      "    to be positive.\n",
      "\n",
      "metric : str or callable, default='minkowski'\n",
      "    Metric to use for distance computation. Default is \"minkowski\", which\n",
      "    results in the standard Euclidean distance when p = 2. See the\n",
      "    documentation of `scipy.spatial.distance\n",
      "    <https://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_ and\n",
      "    the metrics listed in\n",
      "    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric\n",
      "    values.\n",
      "\n",
      "    If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      "    must be square during fit. X may be a :term:`sparse graph`, in which\n",
      "    case only \"nonzero\" elements may be considered neighbors.\n",
      "\n",
      "    If metric is a callable function, it takes two arrays representing 1D\n",
      "    vectors as inputs and must return one value indicating the distance\n",
      "    between those vectors. This works for Scipy's metrics, but is less\n",
      "    efficient than passing the metric name as a string.\n",
      "\n",
      "metric_params : dict, default=None\n",
      "    Additional keyword arguments for the metric function.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    The number of parallel jobs to run for neighbors search.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "    Doesn't affect :meth:`fit` method.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "classes_ : array of shape (n_classes,)\n",
      "    Class labels known to the classifier\n",
      "\n",
      "effective_metric_ : str or callble\n",
      "    The distance metric used. It will be same as the `metric` parameter\n",
      "    or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      "    'minkowski' and `p` parameter set to 2.\n",
      "\n",
      "effective_metric_params_ : dict\n",
      "    Additional keyword arguments for the metric function. For most metrics\n",
      "    will be same with `metric_params` parameter, but may also contain the\n",
      "    `p` parameter value if the `effective_metric_` attribute is set to\n",
      "    'minkowski'.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_samples_fit_ : int\n",
      "    Number of samples in the fitted data.\n",
      "\n",
      "outputs_2d_ : bool\n",
      "    False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
      "    otherwise True.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
      "KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
      "RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
      "NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      "for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      "\n",
      ".. warning::\n",
      "\n",
      "   Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      "   neighbors, neighbor `k+1` and `k`, have identical distances\n",
      "   but different labels, the results will depend on the ordering of the\n",
      "   training data.\n",
      "\n",
      "https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> X = [[0], [1], [2], [3]]\n",
      ">>> y = [0, 0, 1, 1]\n",
      ">>> from sklearn.neighbors import KNeighborsClassifier\n",
      ">>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      ">>> neigh.fit(X, y)\n",
      "KNeighborsClassifier(...)\n",
      ">>> print(neigh.predict([[1.1]]))\n",
      "[0]\n",
      ">>> print(neigh.predict_proba([[0.9]]))\n",
      "[[0.666 0.333]]\n",
      "\u001b[31mFile:\u001b[39m           /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neighbors/_classification.py\n",
      "\u001b[31mType:\u001b[39m           ABCMeta\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()#five is the default value for n_neighbors \n",
    "# KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `KNeighborsClassifier` model with `n_neighbors=50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "knn = KNeighborsClassifier(n_neighbors=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit this model on the data and target loaded above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your model to make predictions on the first 10 data points inside the\n",
    "data. Do they match the actual target values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the test data from `\"../datasets/adult-census-numeric-test.csv\"` and\n",
    "compute the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
