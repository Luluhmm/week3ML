{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Exercise M7.01\n",
    "\n",
    "In this exercise we will define dummy classification baselines and use them as\n",
    "reference to assess the relative predictive performance of a given model of\n",
    "interest.\n",
    "\n",
    "We illustrate those baselines with the help of the Adult Census dataset, using\n",
    "only the numerical features for the sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census-numeric-all.csv\")\n",
    "data, target = adult_census.drop(columns=\"class\"), adult_census[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a `ShuffleSplit` cross-validation strategy taking half of the\n",
    "samples as a testing at each round. Let us use 10 cross-validation rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d02164f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  education-num  capital-gain  capital-loss  hours-per-week   class\n",
       "0   25              7             0             0              40   <=50K\n",
       "1   38              9             0             0              50   <=50K\n",
       "2   28             12             0             0              40    >50K\n",
       "3   44             10          7688             0              40    >50K\n",
       "4   18             10             0             0              30   <=50K"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80ed5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   education-num   48842 non-null  int64 \n",
      " 2   capital-gain    48842 non-null  int64 \n",
      " 3   capital-loss    48842 non-null  int64 \n",
      " 4   hours-per-week  48842 non-null  int64 \n",
      " 5   class           48842 non-null  object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "adult_census.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f582428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_census.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "from sklearn.model_selection import ShuffleSplit,cross_validate\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.5, random_state=0)#half of the data and 10 for cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a machine learning pipeline composed of a transformer to\n",
    "standardize the data followed by a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cross-validation (test) scores for the classifier on this dataset.\n",
    "Store the results pandas Series as we did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.815937\n",
       "1    0.813849\n",
       "2    0.815036\n",
       "3    0.815569\n",
       "4    0.810982\n",
       "5    0.814831\n",
       "6    0.813112\n",
       "7    0.810368\n",
       "8    0.812375\n",
       "9    0.816306\n",
       "Name: Logistic Regression, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "cv_results_logistic_regression = cross_validate(\n",
    "    model, data, target, cv=cv, n_jobs=2\n",
    ")\n",
    "\n",
    "test_score_logistic_regression = pd.Series(\n",
    "    cv_results_logistic_regression[\"test_score\"], name=\"Logistic Regression\"\n",
    ")\n",
    "test_score_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the cross-validation scores of a dummy classifier that constantly\n",
    "predicts the most frequent class observed the training set. Please refer to\n",
    "the online documentation for the [sklearn.dummy.DummyClassifier\n",
    "](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n",
    "class.\n",
    "\n",
    "Store the results in a second pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.760329\n",
       "1    0.756808\n",
       "2    0.759142\n",
       "3    0.760739\n",
       "4    0.761681\n",
       "5    0.761885\n",
       "6    0.757463\n",
       "7    0.757176\n",
       "8    0.761885\n",
       "9    0.763114\n",
       "Name: most freq dummy classifier, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "#for dummy classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "most_freq = DummyClassifier(strategy=\"most_frequent\")\n",
    "cv_results_most_frequent = cross_validate(\n",
    "    most_freq, data, target, cv=cv, n_jobs=2\n",
    ")\n",
    "test_score = pd.Series(\n",
    "    cv_results_most_frequent[\"test_score\"],\n",
    "    name=\"most freq dummy classifier\",\n",
    ")\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we collected the results from the baseline and the model, concatenate\n",
    "the test scores as columns a single pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "# Now that we collected the results from the baseline and the model, concatenate\n",
    "# the test scores as columns a single pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, plot the histogram of the cross-validation test scores for both models\n",
    "with the help of [pandas built-in plotting\n",
    "function](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#histograms).\n",
    "\n",
    "What conclusions do you draw from the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the `strategy` of the dummy classifier to `\"stratified\"`, compute the\n",
    "results. Similarly compute scores for `strategy=\"uniform\"` and then the  plot\n",
    "the distribution together with the other results.\n",
    "\n",
    "Are those new baselines better than the previous one? Why is this the case?\n",
    "\n",
    "Please refer to the scikit-learn documentation on\n",
    "[sklearn.dummy.DummyClassifier](\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n",
    "to find out about the meaning of the `\"stratified\"` and `\"uniform\"`\n",
    "strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
